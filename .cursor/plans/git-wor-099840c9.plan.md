<!-- 099840c9-f022-4fed-927d-a4374321ad2a 95267ecc-836c-4159-b5c1-a71228764ea0 -->
# 数据源统一与 WebUI 创建稳定性修复计划

## 目标

1. **统一数据源为 SQLite**：移除 PostgreSQL 依赖，SQLite 为唯一真实数据源
2. **CSV 仅作初始化**：CSV 仅用于 bootstrap 时一次性导入到 SQLite
3. **对齐 WebUI 与脚本创建**：WebUI 动态创建流程与脚本创建流程完全一致

## 现状分析

### 数据源使用混乱

- **脚本系统**：使用 PostgreSQL（`lib_db.sh`）操作数据库
- **WebUI 后端**：使用 SQLite（`db.py`）操作数据库
- **CSV 文件**：被多处读取作为数据源（bootstrap、create_env.sh、WebUI）

### 脚本创建 vs WebUI 创建差异

**脚本创建流程（稳定）**：

1. 从 PostgreSQL/CSV 读取默认配置
2. 执行 `create_env.sh` 创建集群
3. 等待容器 IP 分配（最多 60 秒）
4. 调用 `db_insert_cluster` 写入 PostgreSQL（带重试）
5. 同步 ApplicationSet

**WebUI 创建流程（不稳定）**：

1. WebUI 调用 `cluster_service.create_cluster`
2. 调用 `create_env.sh` 脚本（✅ 正确）
3. **问题1**：脚本写入 PostgreSQL，WebUI 又写入 SQLite → 数据不一致
4. **问题2**：WebUI 在脚本完成后立即写入 SQLite，但脚本可能还在等待 IP
5. **问题3**：WebUI 数据库操作没有错误处理和重试

## 实施计划

### 阶段 1：创建 SQLite 数据库操作库（脚本系统）

**目标**：为脚本系统创建 SQLite 操作库，替代 `lib_db.sh` 的 PostgreSQL 功能

1. 创建 `scripts/lib_sqlite.sh`

   - 实现 `sqlite_query`, `sqlite_insert_cluster`, `sqlite_get_cluster`, `sqlite_list_clusters` 等函数
   - 使用 `sqlite3` 命令操作 SQLite 数据库
   - 数据库路径：`/data/kindler-webui/kindler.db`（与 WebUI 共享）
   - 添加文件锁机制（flock）确保并发安全

2. 修改 `create_env.sh`

   - 移除 `lib_db.sh` 依赖
   - 添加 `lib_sqlite.sh` 依赖
   - 将 `db_insert_cluster` 替换为 `sqlite_insert_cluster`
   - 将 `db_get_cluster` 替换为 `sqlite_get_cluster`
   - 保持相同的错误处理和重试逻辑

### 阶段 2：统一数据源访问

**目标**：所有脚本和 WebUI 都使用 SQLite

1. 修改所有使用 `lib_db.sh` 的脚本

   - `bootstrap.sh`：初始化时从 CSV 导入到 SQLite
   - `delete_env.sh`：删除时从 SQLite 删除记录
   - `list_env.sh`：从 SQLite 读取列表
   - `sync_applicationset.sh`：从 SQLite 读取集群列表
   - `sync_git_from_db.sh`：从 SQLite 读取集群列表
   - `haproxy_sync.sh`：从 SQLite 读取（如果支持）或保持 CSV
   - 其他依赖 `lib_db.sh` 的脚本

2. 统一 CSV 使用方式

   - CSV 仅在 bootstrap 时使用（一次性导入到 SQLite）
   - `create_env.sh` 不再从 CSV 读取，只从 SQLite 读取默认配置
   - 如果 SQLite 中没有记录，使用硬编码默认值

### 阶段 3：修复 WebUI 创建流程

**目标**：WebUI 创建流程与脚本创建完全一致

1. 修复 `cluster_service.py`

   - **移除重复数据库写入**：`create_env.sh` 已写入 SQLite，WebUI 不再写入
   - **等待脚本完全完成**：确保脚本的所有步骤（包括 IP 分配）都完成
   - **添加错误处理**：如果脚本失败，不写入数据库
   - **对齐参数传递**：确保 WebUI 传递给脚本的参数与直接调用脚本一致

2. 比对脚本创建的关键步骤

   - **容器 IP 等待**：脚本有等待容器 IP 的逻辑（60 秒），WebUI 需要确保这一步完成
   - **重试机制**：脚本有数据库写入重试（3 次），WebUI 依赖脚本的重试
   - **ApplicationSet 同步**：脚本在数据库写入后同步 ApplicationSet，WebUI 不需要额外操作

### 阶段 4：移除 PostgreSQL 依赖

**目标**：完全移除 PostgreSQL 相关代码

1. 移除 PostgreSQL 相关脚本

   - `scripts/deploy_postgresql.sh`
   - `scripts/deploy_postgresql_gitops.sh`
   - `scripts/setup_postgresql_nodeport.sh`
   - `scripts/lib_db.sh`（替换为 lib_sqlite.sh）
   - `scripts/init_database.sh`（修改为初始化 SQLite）

2. 移除 PostgreSQL 相关配置

   - 从 `bootstrap.sh` 移除 PostgreSQL 部署逻辑
   - 从 ArgoCD manifests 移除 PostgreSQL Application
   - 从 `compose/infrastructure/docker-compose.yml` 移除 PostgreSQL 相关（如果有）

3. 清理 PostgreSQL 相关文档

   - 更新文档，说明使用 SQLite 而非 PostgreSQL
   - 移除 PostgreSQL 相关的测试脚本

### 阶段 5：CSV 初始化流程

**目标**：确保 CSV 仅用于初始化

1. 修改 `bootstrap.sh`

   - 在 WebUI 启动前，从 CSV 导入数据到 SQLite
   - 使用 WebUI 的 `db.py` 的 `sync_from_csv` 方法（通过 Python 脚本调用）
   - 或创建独立的 CSV→SQLite 导入脚本

2. 确保幂等性

   - CSV 导入应该是幂等的（如果记录已存在则更新）
   - 用户修改 CSV 后，重建环境时自动重新导入

### 阶段 6：更新项目规则文档

**目标**：将数据源统一规则固化到项目规则文件中

1. 更新 `AGENTS.md`

   - 说明 SQLite 是唯一真实数据源
   - 说明 CSV 仅用于初始化（bootstrap 时一次性导入）
   - 说明 PostgreSQL 已被移除
   - 说明并发操作支持机制（文件锁、事务）

2. 更新 `CLAUDE.md`（如果存在）或合并到 `AGENTS.md`

   - 说明数据源架构
   - 说明并发安全机制
   - 说明脚本创建与 WebUI 创建的流程一致性

3. 更新 `.cursorrules`

   - 添加数据源规则：SQLite 唯一、CSV 仅初始化
   - 添加并发操作规则：使用文件锁、事务确保原子性
   - 添加开发规范：脚本和 WebUI 必须使用 SQLite

4. 更新 `README.md` 和 `README_CN.md`

   - 说明数据存储架构（SQLite）
   - 移除 PostgreSQL 相关说明
   - 说明 CSV 的作用（仅初始化）

### 阶段 7：测试与验证

**目标**：确保所有功能正常

1. 测试脚本创建

   - 从 SQLite 读取配置
   - 创建后写入 SQLite
   - 验证数据一致性

2. 测试 WebUI 创建

   - 通过 WebUI 创建集群
   - 验证与脚本创建结果一致
   - 验证数据库记录正确

3. 测试数据一致性

   - 脚本创建和 WebUI 创建都写入同一个 SQLite 数据库
   - 所有读取操作都从 SQLite 读取
   - 验证无数据不一致

4. 测试并发操作

   - 并发创建不同集群（验证端口分配正确）
   - 并发创建同名集群（验证只有一个成功）
   - 并发创建使用相同端口（验证自动分配机制）
   - 并发读取和写入（验证数据一致性）

## 实施细节

### SQLite 操作库实现要点（并发安全）

```bash
# scripts/lib_sqlite.sh
SQLITE_DB="/data/kindler-webui/kindler.db"
SQLITE_LOCK="/tmp/kindler_db.lock"

sqlite_query() {
  # 使用 flock 加锁，确保并发安全（独占锁）
  # 超时设置：最多等待 30 秒
  (
    flock -x -w 30 200 || {
      echo "[ERROR] Failed to acquire database lock after 30s" >&2
      return 1
    }
    sqlite3 "$SQLITE_DB" "$@"
  ) 200>"$SQLITE_LOCK"
}

sqlite_transaction() {
  # 执行事务操作（确保原子性）
  local sql="$1"
  sqlite_query "
    BEGIN IMMEDIATE TRANSACTION;
    $sql
    COMMIT;
  "
}

sqlite_insert_cluster() {
  # 实现与 db_insert_cluster 相同的功能
  # 使用事务确保原子性（防止并发插入冲突）
  sqlite_transaction "
    INSERT OR REPLACE INTO clusters 
      (name, provider, subnet, node_port, pf_port, http_port, https_port, server_ip, updated_at)
    VALUES 
      ('$name', '$provider', '${subnet:-}', $node_port, $pf_port, $http_port, $https_port, '${server_ip:-}', datetime('now'));
  "
}

sqlite_check_port_available() {
  # 原子性检查端口是否可用（避免并发创建时端口冲突）
  # 使用事务锁确保读取-检查-写入的原子性
  local port="$1"
  local result
  result=$(sqlite_transaction "
    SELECT COUNT(*) FROM clusters 
    WHERE node_port = $port OR pf_port = $port OR http_port = $port OR https_port = $port;
  ")
  [ "$result" -eq 0 ]
}

sqlite_allocate_port() {
  # 原子性分配下一个可用端口（避免并发创建时端口冲突）
  # 使用事务确保端口分配的原子性
  local start="$1"
  local end="$2"
  local field="${3:-node_port}"  # node_port, pf_port, http_port, https_port
  
  for port in $(seq "$start" "$end"); do
    if sqlite_check_port_available "$port" "$field"; then
      echo "$port"
      return 0
    fi
  done
  return 1
}

sqlite_cluster_exists() {
  # 原子性检查集群是否存在（避免并发创建同名集群）
  local name="$1"
  local count
  count=$(sqlite_transaction "SELECT COUNT(*) FROM clusters WHERE name = '$name';")
  [ "$count" -gt 0 ]
}
```

### 并发操作支持机制

#### 1. 脚本级并发控制

- **集群名称锁**：同一时间只能创建一个同名集群
  - 使用文件锁：`/tmp/kindler_create_${name}.lock`
  - 如果锁存在，等待或失败
  - 创建开始时获取锁，完成或失败时释放

- **端口分配原子性**：
  - 使用数据库事务确保端口分配的原子性
  - 检查-分配-写入在同一个事务中完成
  - 如果端口被占用，自动分配下一个可用端口

- **数据库操作锁**：
  - 所有数据库操作使用 flock（文件锁）
  - 锁定时间尽量短（读写分离）
  - 超时设置避免死锁

#### 2. WebUI 后端并发控制

- **任务队列**：WebUI 后端已实现任务管理器（task_manager）
  - 同一集群的创建/删除操作排队执行
  - 不同集群的创建可以并发（受系统资源限制）

- **数据库连接池**：SQLite 支持多个读连接
  - 读操作可以并发（不需要锁）
  - 写操作需要独占锁（通过 flock 实现）

- **脚本执行锁**：
  - WebUI 调用脚本时，脚本内部已实现锁机制
  - 确保同一集群不会同时被创建多次

#### 3. 端口冲突处理

- **自动分配**：如果指定端口被占用，自动分配下一个可用端口
- **冲突检测**：创建前检查端口是否可用（原子操作）
- **回退机制**：如果自动分配失败，返回错误而非继续

#### 4. 集群名称冲突处理

- **创建前检查**：使用 `sqlite_cluster_exists` 原子性检查
- **创建中保护**：使用文件锁保护创建过程
- **创建后验证**：验证集群是否真正创建成功

### WebUI 创建流程修复（并发安全）

```python
# cluster_service.py
async def create_cluster(self, cluster_data, progress_callback):
    name = cluster_data["name"]
    
    # 1. 检查集群是否已存在（使用数据库原子操作）
    if await db_service.cluster_exists(name):
        raise HTTPException(status_code=409, detail=f"Cluster {name} already exists")
    
    # 2. 检查并分配端口（原子操作）
    if "node_port" not in cluster_data:
        # 从数据库读取默认值或自动分配
        available_port = await db_service.allocate_port(...)
        cluster_data["node_port"] = available_port
    
    # 3. 执行 create_env.sh（脚本内部有锁保护）
    # 脚本会：
    #   - 获取集群名称锁
    #   - 检查端口可用性（原子操作）
    #   - 创建集群
    #   - 写入数据库（带锁）
    success = await self._run_script("create_env.sh", args, ...)
    
    # 4. 如果成功，脚本已经写入 SQLite，WebUI 不需要再写入
    # 5. 验证脚本输出，确保所有步骤完成（包括 IP 分配）
    if success:
        # 验证集群是否真正创建成功（kubectl 检查）
        status = await self.get_cluster_status(name, cluster_data["provider"])
        if status["status"] != "running":
            # 创建失败，但脚本已写入部分数据，需要清理
            await db_service.delete_cluster(name)
            return False
    
    return success
```

### 并发操作测试场景

1. **并发创建不同集群**：

   - 同时创建 dev, uat, prod
   - 验证都成功创建
   - 验证端口无冲突
   - 验证数据库记录正确

2. **并发创建同名集群**：

   - 同时尝试创建同名集群
   - 验证只有一个成功
   - 验证另一个返回 409 冲突错误

3. **并发创建使用相同端口**：

   - 同时指定相同端口创建集群
   - 验证自动端口分配机制
   - 验证无端口冲突

4. **并发读取和写入**：

   - 多个 WebUI 请求同时读取集群列表
   - 同时进行创建操作
   - 验证数据一致性

## 最小变更原则

- 保持脚本创建流程不变（只改变数据源）
- WebUI 创建流程与脚本创建流程对齐（移除重复操作）
- CSV 文件格式保持不变（仅改变使用方式）
- 数据库 Schema 保持兼容（SQLite 表结构对应 PostgreSQL）